{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "################## IMPORTACIÓ DE LLIBRERIES\n",
    "###########################################\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "############################## funció get_link()\n",
    "# Obtenció del link al qual es farà el scraper.\n",
    "################################################\n",
    "# var entrada:\n",
    "# player_sel: jugador que es vol analitzar.\n",
    "# season: temporada que es vol analitzar.\n",
    "# var de sortida:\n",
    "# link_pl_seas: link complet al qual es realitzarà el scraper.\n",
    "#       i.e.: https://www.basketball-reference.com/players/g/gasolpa01.html\n",
    "\n",
    "def get_link(player_sel, season):\n",
    "    stop = False\n",
    "    url = 'https://www.basketball-reference.com/players/'\n",
    "    alph = string.ascii_lowercase #Creació de l'alfabet\n",
    "    \n",
    "    for letter in alph:\n",
    "        url_alph = url + letter\n",
    "        page_home = requests.get(url_alph)\n",
    "        soup_home = BeautifulSoup(page_home.content, 'html.parser')\n",
    "        players_list = soup_home.find_all('a',href=True)\n",
    "\n",
    "        for player in players_list:\n",
    "            if player.find(text = True) == player_sel: \n",
    "                link = player.get('href')\n",
    "                link_player = url_alph + link[10:].split('.')[0] # link elimino /players/ i .htm\n",
    "                link_pl_seas = link_player + '/gamelog/' + str(season)\n",
    "                stop = True\n",
    "                break\n",
    "        if stop == True: break\n",
    "    return(link_pl_seas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "############################## funció get_info()\n",
    "# Obtenció de les dades per generar el dataset.\n",
    "################################################\n",
    "# var entrada:\n",
    "# link_study: link obtingut de la funció get_link().\n",
    "# var sortida:\n",
    "# all_match: llista amb les dades extretes del jugador.\n",
    "\n",
    "def get_info(link_study):\n",
    "    page_study = requests.get(link_study)\n",
    "    soup_study = BeautifulSoup(page_study.content, 'html.parser')\n",
    "    \n",
    "    all_tables = soup_study.find_all('table')\n",
    "    for tables in all_tables:\n",
    "        table = tables.find('tbody')\n",
    "\n",
    "    all_match = []\n",
    "    header_match = ['Date', 'Opp', 'W/L', 'time', '2P', '3P', '1P', 'Off Reb', 'Def Reb', 'Assist', 'Steal', 'Foul', 'Points', 'Game Score']\n",
    "    all_match.append(header_match)\n",
    "\n",
    "    for row in table.find_all(\"tr\", id = True):\n",
    "        cells = row.find_all('td')\n",
    "        date = cells[1].find(text=True)\n",
    "        opponent = cells[5].find(text=True)\n",
    "        result = cells[6].find(text=True)[0] # és un string on la primera lletra indica W o L.\n",
    "        minutes = cells[8].find(text=True)\n",
    "        t3 = int(cells[12].find(text=True))\n",
    "        t2 = int(cells[9].find(text=True)) - t3 # Total tirs de camp - tirs de 3\n",
    "        t1 = int(cells[15].find(text=True))\n",
    "        off_reb = int(cells[18].find(text=True))\n",
    "        def_reb = int(cells[19].find(text=True))\n",
    "        assist = int(cells[21].find(text=True))\n",
    "        steal = int(cells[22].find(text=True))\n",
    "        foul = int(cells[25].find(text=True))\n",
    "        points = int(cells[26].find(text=True))\n",
    "        score = float(cells[27].find(text=True))\n",
    "\n",
    "        all_match.append([date, opponent, result, minutes, t2, t3, t1, off_reb, def_reb, assist, steal, foul, points, score])\n",
    " \n",
    "    return(all_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "############################### funció get_csv()\n",
    "# Creació de l'arxiu csv\n",
    "################################################\n",
    "# var entrada:\n",
    "# all_match: llista amb les dades extretes del jugador.\n",
    "# player_sel: jugador que s'ha analitzat.\n",
    "# season: temporada que s'ha analitzat\n",
    "\n",
    "def get_csv(all_match, player_sel, season):\n",
    "    player = player_sel.replace(' ', '_')\n",
    "    filename = player + '_season_' + str(season) + '.csv'\n",
    "    with open(filename, 'w', newline='') as csvFile:\n",
    "        matchWriter = csv.writer(csvFile, delimiter = ';')\n",
    "        for match in all_match:\n",
    "            matchWriter.writerow(match)\n",
    "    print('Dataset ' + filename + ' created ! !')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter player name and surname (i.e. Pau Gasol): Pau Gasol\n",
      "Please enter season (i.e. 2018): 2010\n",
      "\n",
      "  Executing scraper\n",
      "\n",
      "Dataset Pau_Gasol_season_2010.csv created ! !\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "########################### EXECUCIÓ DEL SCRAPER\n",
    "# Sol·licitud de les variables d'entrada + crida\n",
    "# de les funcions prèviament definides.\n",
    "################################################\n",
    "\n",
    "player = str(input('Please enter player name and surname (i.e. Pau Gasol): '))\n",
    "season = str(input('Please enter season (i.e. 2018): '))\n",
    "\n",
    "print('\\n  Executing scraper\\n')\n",
    "try:\n",
    "    link_study = get_link(player, season)\n",
    "    try:\n",
    "        info_matches = get_info(link_study)\n",
    "    except Exception as e: print('ERROR: Season not found...')\n",
    "except Exception as e: print('ERROR: Player not found...')\n",
    "get_csv(info_matches, player, season)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
